#!/usr/bin/env python3
"""
Example of the multilingual review agent with English and Japanese support.
This demonstrates how the agent can switch between languages and provide
appropriate responses in both English and Japanese.
"""

import asyncio
import os

from dotenv import load_dotenv

from src.langgraph_server.agent import create_agent
from src.langgraph_server.prompt import build_restaurant_prompt

load_dotenv()


async def run_english_example():
    """Run the agent with English prompts."""

    print("ğŸ‡ºğŸ‡¸ English Example")
    print("=" * 50)

    # Create the agent
    graph = await create_agent()

    # Thread configuration
    thread_config = {
        "configurable": {
            "thread_id": "english-demo-thread",
            "user_id": "demo-user",
        },
        "recursion_limit": 25,
    }

    # English query
    request = build_restaurant_prompt(
        location="San Francisco, CA",
        preferences="Italian cuisine, romantic atmosphere, and excellent service",
        language="en",
    )

    print("ğŸ” Searching for Italian restaurants in San Francisco...")
    print("-" * 50)

    # Stream the response
    async for event in graph.astream(request, config=thread_config):
        if "model" in event:
            msg = event["model"]["messages"]
            try:
                content = getattr(msg, "content", None) or str(msg)
            except Exception:
                content = str(msg)
            if content:
                print(content)


async def run_japanese_example():
    """Run the agent with Japanese prompts."""

    print("\nğŸ‡¯ğŸ‡µ Japanese Example")
    print("=" * 50)

    # Create the agent
    graph = await create_agent()

    # Thread configuration
    thread_config = {
        "configurable": {
            "thread_id": "japanese-demo-thread",
            "user_id": "demo-user",
        },
        "recursion_limit": 25,
    }

    # Japanese query
    request = build_restaurant_prompt(
        location="æ–°å®¿ã€æ±äº¬ã€æ—¥æœ¬",
        preferences="æœ¬æ ¼çš„ãªãƒ©ãƒ¼ãƒ¡ãƒ³ã€ä¼çµ±çš„ãªé›°å›²æ°—ã€åœ°å…ƒã®äººæ°—åº—",
        language="jp",
    )

    print("ğŸ” æ–°å®¿ã§æœ¬æ ¼çš„ãªãƒ©ãƒ¼ãƒ¡ãƒ³åº—ã‚’æ¤œç´¢ä¸­...")
    print("-" * 50)

    # Stream the response
    async for event in graph.astream(request, config=thread_config):
        if "model" in event:
            msg = event["model"]["messages"]
            try:
                content = getattr(msg, "content", None) or str(msg)
            except Exception:
                content = str(msg)
            if content:
                print(content)


async def run_comparison_example():
    """Run both English and Japanese examples for comparison."""

    print("ğŸ”„ Language Comparison Example")
    print("=" * 60)

    # Create the agent
    graph = await create_agent()

    # Thread configuration
    thread_config = {
        "configurable": {
            "thread_id": "comparison-demo-thread",
            "user_id": "demo-user",
        },
        "recursion_limit": 25,
    }

    # English query
    print("\nğŸ‡ºğŸ‡¸ English Query:")
    print("Location: New York, NY")
    print("Preferences: Affordable sushi, fresh fish, and casual dining")
    print("-" * 40)

    request_en = build_restaurant_prompt(
        location="New York, NY",
        preferences="affordable sushi, fresh fish, and casual dining",
        language="en",
    )

    async for event in graph.astream(request_en, config=thread_config):
        if "model" in event:
            msg = event["model"]["messages"]
            try:
                content = getattr(msg, "content", None) or str(msg)
            except Exception:
                content = str(msg)
            if content:
                print(content)

    # Japanese query
    print("\nğŸ‡¯ğŸ‡µ Japanese Query:")
    print("Location: æ¸‹è°·ã€æ±äº¬ã€æ—¥æœ¬")
    print("Preferences: æ‰‹é ƒãªä¾¡æ ¼ã®å¯¿å¸ã€æ–°é®®ãªé­šã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªé›°å›²æ°—")
    print("-" * 40)

    request_jp = build_restaurant_prompt(
        location="æ¸‹è°·ã€æ±äº¬ã€æ—¥æœ¬",
        preferences="æ‰‹é ƒãªä¾¡æ ¼ã®å¯¿å¸ã€æ–°é®®ãªé­šã€ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªé›°å›²æ°—",
        language="jp",
    )

    async for event in graph.astream(request_jp, config=thread_config):
        if "model" in event:
            msg = event["model"]["messages"]
            try:
                content = getattr(msg, "content", None) or str(msg)
            except Exception:
                content = str(msg)
            if content:
                print(content)


async def run_interactive_example():
    """Run an interactive example where user can choose language and preferences."""

    print("ğŸ¯ Interactive Multilingual Example")
    print("=" * 50)

    # Get user input
    print("\nChoose your language:")
    print("1. English")
    print("2. Japanese")

    lang_choice = input("Enter your choice (1 or 2): ").strip()
    language = "jp" if lang_choice == "2" else "en"

    if language == "jp":
        print("\nå ´æ‰€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: æ–°å®¿ã€æ±äº¬ã€æ—¥æœ¬):")
        location = input("Location: ").strip() or "æ–°å®¿ã€æ±äº¬ã€æ—¥æœ¬"

        print("\nå¥½ã¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (ä¾‹: æœ¬æ ¼çš„ãªãƒ©ãƒ¼ãƒ¡ãƒ³ã€ä¼çµ±çš„ãªé›°å›²æ°—):")
        preferences = (
            input("Preferences: ").strip() or "æœ¬æ ¼çš„ãªãƒ©ãƒ¼ãƒ¡ãƒ³ã€ä¼çµ±çš„ãªé›°å›²æ°—"
        )
    else:
        print("\nEnter location (e.g., San Francisco, CA):")
        location = input("Location: ").strip() or "San Francisco, CA"

        print("\nEnter preferences (e.g., Italian cuisine, romantic atmosphere):")
        preferences = (
            input("Preferences: ").strip() or "Italian cuisine, romantic atmosphere"
        )

    # Create the agent
    graph = await create_agent()

    # Thread configuration
    thread_config = {
        "configurable": {
            "thread_id": f"interactive-{language}-thread",
            "user_id": "demo-user",
        },
        "recursion_limit": 25,
    }

    # Build request
    request = build_restaurant_prompt(
        location=location, preferences=preferences, language=language
    )

    print("\nğŸ” Searching for restaurants...")
    print("-" * 50)

    # Stream the response
    async for event in graph.astream(request, config=thread_config):
        if "model" in event:
            msg = event["model"]["messages"]
            try:
                content = getattr(msg, "content", None) or str(msg)
            except Exception:
                content = str(msg)
            if content:
                print(content)


async def main():
    """Main function to run multilingual examples."""

    print("ğŸŒ Multilingual Review Agent Demo")
    print("Supporting English and Japanese")
    print("=" * 60)

    # Check if we have the required API keys
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY is required for the agent to work")
        print("Please set it in your .env file")
        return

    # Choose which example to run
    print("\nChoose an example to run:")
    print("1. English example")
    print("2. Japanese example")
    print("3. Language comparison")
    print("4. Interactive example")

    choice = input("\nEnter your choice (1-4): ").strip()

    if choice == "1":
        await run_english_example()
    elif choice == "2":
        await run_japanese_example()
    elif choice == "3":
        await run_comparison_example()
    elif choice == "4":
        await run_interactive_example()
    else:
        print("Invalid choice. Running English example...")
        await run_english_example()


if __name__ == "__main__":
    asyncio.run(main())
